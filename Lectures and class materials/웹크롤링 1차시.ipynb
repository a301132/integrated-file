{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1차시\n",
    "#### - Web 개발자도구 옵션 활용방법\n",
    "#### - 사용환경설정\n",
    "## 2차시\n",
    "#### - 정적 웹크롤링\n",
    "#### - 동적 웹크롤링\n",
    "#### - 스크래핑 데이터 저장\n",
    "## 3차시\n",
    "#### - 데이터 전처리(Konlpy 활용)\n",
    "## 4차시\n",
    "#### - 워드클라우드(Wordcloud)\n",
    "#### - 연관성 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 웹 크롤링(Web Crawling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=https://prowebscraper.com/blog/wp-content/uploads/2017/11/Web_Scraping_for_Non-Programmers.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Website 또는 HTML Page를 어떠한 Scraping Tools을 통하여 필요한 데이터를 추출하는 방법이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scraping Tool은 Python을 사용할 것이며 웹 페이지에서 텍스트, 이미지, 테이블 등을 Scraping 하는 방법을 배울 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python으로 Scraping을 하기 전에 Website가 어떻게 생겼는지 어떠한 부분을 추출해야하는지를 알아보자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web 개발자 도구옵션"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 웹페이지는 다양한 언어들이 모여서 하나의 페이지를 만드는데 크게 총 3가지로 이루어진다.(css, Javascript, HTML)\n",
    "#### 3가지 언어로 어떻게 웹페이지가 구성되었는지 먼저 확인해 보자. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=webimage1.png width='1500'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 위 이미지는 네이버 뉴스에 들어가서 F12를 누른 것이다.\n",
    "#### F12를 누르게 되면 이미지의 오른쪽에 나타난 것처럼 webpage들의 속성을 확인할 수 있다.\n",
    "#### 오른쪽에 있는 수많은 코드들이 우리가 보는 웹페이지들의 구성 코드입니다.\n",
    "#### 이것들은 위에서 말했듯이 css, Javascript, HTML 언어들을 사용한 것이다.\n",
    "#### 자 그러면 우리가 보는 웹페이지에서 어떠한 이미지 또는 텍스트가 어떤 코드로 작성되었는지를 확인해보고 싶다.\n",
    "#### 개발자도구에서 왼쪽 위에 있는 마우스커서처럼 생긴 것을 클릭하고\n",
    "#### 왼쪽의 이미지나 코드를 클릭하게 되면 개발자도구에서 그것에 해당하는 코드를 보여준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=web2.png width='1500'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 이제 우리는 웹 페이지에서 텍스트나 이미지가 어떠한 코드로 구성되었는지 알았다.\n",
    "#### 웹 페이지에서 우리가 필요한 데이터를 구성된 코드를 통해서 웹 크롤링을 할 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사용환경설정\n",
    "#### 만약 동적인 웹 크롤링(Web crawling)을 사용할 때, Colab은 3시간 정도되면 연결이 끊키기 때문에 Local에 jupyter notebook이나 anaconda를 설치하고 진행하는 것을 추천드립니다.\n",
    "#### 또한 웹 크롤링 차시에는 local python에서 사용하기 때문에 colab에서 작동이 안될 수 도 있다는 것을 먼저 말해드립니다.\n",
    "#### https://blog.naver.com/PostView.nhn?blogId=chandong83&logNo=222128977072&redirect=Dlog&widgetTypeCall=true&directAccess=false\n",
    "#### anaconda 설치방법은 블로그에서 잘 설명해주어서 링크를 타고 들어가서 순서대로 실행해주시면 됩니다.\n",
    "#### 그리고 anaconda를 실행하고 여러개 application이 있는데 Jupyter notebook이나 Jupyterlab을 사용하시면 됩니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 그러면 웹크롤링의 타겟을 알게되었고, 크롤링에 사용할 Tool의 설치까지 완료되었습니다. \n",
    "#### 다음시간부터 웹 크롤링을 하는 방법들을 알려드리겠습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
